{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 2007\n",
    "year_end = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthToNum(shortMonth):\n",
    "    return{\n",
    "            'January' : 1,\n",
    "            'February' : 2,\n",
    "            'March' : 3,\n",
    "            'April' : 4,\n",
    "            'May' : 5,\n",
    "            'June' : 6,\n",
    "            'July' : 7,\n",
    "            'August' : 8,\n",
    "            'September' : 9, \n",
    "            'October' : 10,\n",
    "            'November' : 11,\n",
    "            'December' : 12\n",
    "    }[shortMonth]\n",
    "\n",
    "def finalRoundNum(final):\n",
    "    return{\n",
    "        'First Qualifying Final' : 30,\n",
    "        'Second Qualifying Final' : 30,\n",
    "        'Qualifying Final' : 30,\n",
    "        'First Elimination Final' : 30,\n",
    "        'Second Elimination Final' : 30,\n",
    "        'Elimination Final' : 30,\n",
    "        'First Semi Final' : 31,\n",
    "        'Second Semi Final' : 31,\n",
    "        'First Semi-Final' : 31,\n",
    "        'Second Semi-Final' : 31,\n",
    "        'Semi Final' : 31,\n",
    "        'First Preliminary Final': 32,\n",
    "        'Second Preliminary Final': 32,\n",
    "        'Preliminary Final': 32,\n",
    "        'Grand Final' : 33\n",
    "    }[final]\n",
    "\n",
    "def getOdds(data):\n",
    "    try:\n",
    "        odds = data.str.split(',')\n",
    "        odds = odds[0][0]\n",
    "        odds = float(odds.split(': Win ')[1])\n",
    "    except:\n",
    "        odds = 0\n",
    "    return odds\n",
    "def getLine(data):\n",
    "    try:\n",
    "        line = data.str.split(',')[0][1]\n",
    "        line = re.sub(' @ 1.92','', re.sub(' Line ', '', line))\n",
    "    except:\n",
    "        line = 0\n",
    "    return line\n",
    "def getSoup(url):\n",
    "    html = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoTable(some_soup):\n",
    "    info_table = some_soup.find('table', border=\"0\", cellpadding=\"0\", cellspacing=\"0\", width=\"525\") #find the first table with this info\n",
    "    info_table = pd.read_html(str(info_table))\n",
    "    info_table = info_table[0]\n",
    "    return info_table\n",
    "def dateTime(the_info_table):\n",
    "    date_time = the_info_table.iloc[2]\n",
    "    date_time = date_time.str.split(',')\n",
    "    date = date_time[0][1].split(' ')\n",
    "    day = re.sub('[^0-9]','',date[1])\n",
    "    year = date[3]\n",
    "    month = monthToNum(date[2])\n",
    "    time = date_time[0][2].split(' ')\n",
    "    date = datetime.datetime(int(year), month, int(day))\n",
    "    return date\n",
    "def getGameInfo(the_info_table):\n",
    "    game_info = the_info_table.iloc[1]\n",
    "    game_info = game_info.str.split(',')\n",
    "    return game_info\n",
    "def getStatTable(some_soup):\n",
    "    stat_table = some_soup.find('table', border=\"0\", cellpadding=\"0\", cellspacing=\"0\", width=\"575\") #find the first table with this info\n",
    "    stat_table = pd.read_html(str(stat_table))[0]\n",
    "    return stat_table\n",
    "def getStats(the_stat_table, team, stat_type):\n",
    "    if team == 'home':\n",
    "        col_num = 0\n",
    "    if team == 'away':\n",
    "        col_num = 2\n",
    "    if stat_type == 'basic':\n",
    "        last_row = 27\n",
    "    if stat_type == 'advanced':\n",
    "        last_row = 22\n",
    "    stats = pd.Series(data =  the_stat_table.iloc[2:last_row,col_num]).str.replace('%','').astype('float')\n",
    "    return stats\n",
    "def replacePcnt(data):\n",
    "    data = data.str.replace('% ','').str.replace(' %','').str.replace('%','').str.replace(' ', '_')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeGameData(soup):\n",
    "    #isolate table with the initial info and get date and year\n",
    "    info_table = infoTable(soup)\n",
    "    date = dateTime(info_table)\n",
    "    year = date.year\n",
    "\n",
    "    #get the round, location and attendance for the game from the table with initial info\n",
    "    game_info = getGameInfo(info_table)\n",
    "    the_round = game_info[0][0]\n",
    "    #if the round is a final use the final name and the number from the function finalRoundNum, else use the actual number. Ac \n",
    "    if 'Final' in the_round:\n",
    "        round_char = the_round\n",
    "        season_round = finalRoundNum(the_round)\n",
    "        final = 1\n",
    "    else:\n",
    "        round_char = re.sub('[^0-9]', '', the_round)\n",
    "        season_round = int(re.sub('[^0-9]', '', the_round))\n",
    "        final = 0\n",
    "    location = game_info[0][1]\n",
    "    attendance = int(re.sub(' Attendance: ', '', game_info[0][2]))\n",
    "\n",
    "    #get the odds and line from the table with initial info\n",
    "    try:\n",
    "        home_odds = getOdds(info_table.iloc[3])\n",
    "    except:\n",
    "        home_odds = 0\n",
    "    try:\n",
    "        away_odds = getOdds(info_table.iloc[4])\n",
    "    except:\n",
    "        away_odds = 0\n",
    "    try:\n",
    "        home_line = getLine(info_table.iloc[3])\n",
    "    except:\n",
    "        home_line = 0        \n",
    "    try:\n",
    "        away_line = getLine(info_table.iloc[4])\n",
    "    except:\n",
    "        away_line = 0 \n",
    "    #isolate the stats table, get basic stats and home/away teams\n",
    "    bsc_stat_tbl = getStatTable(soup)\n",
    "    bsc_home_stats = getStats(bsc_stat_tbl, 'home', 'basic')\n",
    "    bsc_away_stats = getStats(bsc_stat_tbl, 'away', 'basic')\n",
    "    bsc_stat_lbl = replacePcnt(pd.Series(data =  bsc_stat_tbl.iloc[2:27,1]))\n",
    "    home_team = bsc_stat_tbl.iloc[1,1]\n",
    "    away_team = bsc_stat_tbl.iloc[1,3]\n",
    "\n",
    "    #create the column names for the data frame\n",
    "    header_cols = pd.Series(['fw_game_id', 'year', 'season_round',  'round_char', 'date', 'team', 'opponent', 'home_game', 'location', 'attendance', 'final',\n",
    "               'team_odds', 'oppnt_odds', 'team_line', 'oppnt_line'])\n",
    "\n",
    "    try:\n",
    "        #scrape the advanced stats table\n",
    "        afl_adv_url = afl_url + '&advv=Y'\n",
    "        advanced_soup = getSoup(afl_adv_url)\n",
    "\n",
    "        #scrape the advanced stat\n",
    "        adv_stat_tbl = getStatTable(advanced_soup)\n",
    "        adv_home_stats = getStats(adv_stat_tbl, 'home', 'advanced')\n",
    "        adv_away_stats = getStats(adv_stat_tbl, 'away', 'advanced')\n",
    "        adv_stat_lbl = replacePcnt(pd.Series(data =  adv_stat_tbl.iloc[2:22,1]))\n",
    "\n",
    "        header_cols = pd.concat([header_cols,\n",
    "                  bsc_stat_lbl + 'Team', adv_stat_lbl + 'Team',\n",
    "                   bsc_stat_lbl + 'Oppnt', adv_stat_lbl + 'Oppnt'], \n",
    "                 axis = 0).reset_index(drop=True)\n",
    "        \n",
    "    #when there are no advanced stats....\n",
    "    except:\n",
    "        header_cols = pd.concat([header_cols,\n",
    "                  bsc_stat_lbl + 'Team', bsc_stat_lbl + 'Oppnt'], \n",
    "                 axis = 0).reset_index(drop=True)\n",
    "\n",
    "    #create the data frame with column names\n",
    "    game_DF = pd.DataFrame(columns = header_cols)\n",
    "\n",
    "    #add the home team data to the data frame\n",
    "    game_meta = pd.Series([game_id, year, season_round, round_char, date, home_team, away_team, 1, location, attendance, final,\n",
    "               home_odds, away_odds, home_line, away_line])\n",
    "    game_stats = pd.concat([bsc_home_stats, adv_home_stats, bsc_away_stats, adv_away_stats])\n",
    "    game_data = pd.concat([game_meta, game_stats])\n",
    "    game_data.index = header_cols\n",
    "    game_DF = game_DF.append(game_data, ignore_index=True)\n",
    "\n",
    "    #add the away team data to the data frame\n",
    "    game_meta = pd.Series([game_id, year, season_round, round_char, date, away_team, home_team, 0, location, attendance, final,\n",
    "               away_odds, home_odds, away_line, home_line])\n",
    "    game_stats = pd.concat([bsc_away_stats, adv_away_stats, bsc_home_stats, adv_home_stats])\n",
    "    game_data = pd.concat([game_meta, game_stats])\n",
    "    game_data.index = header_cols\n",
    "    game_DF = game_DF.append(game_data, ignore_index=True)\n",
    "    #clean up columns, remove nan\n",
    "    game_DF = game_DF[[col for col in game_DF.columns if str(col) != 'nan']]\n",
    "    game_DF = game_DF.loc[:,~game_DF.columns.duplicated()]\n",
    "    return game_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = []\n",
    "for year in range(year_start,year_end + 1):\n",
    "    try:\n",
    "        afl_year_url = 'https://www.footywire.com/afl/footy/ft_match_list?year=' + str(year)\n",
    "        soup = getSoup(afl_year_url)\n",
    "        for a in soup.find_all(\"a\", href=re.compile(r\"^ft_match_statistics\")):\n",
    "            game_ids.append(\n",
    "                int(a['href'].replace('ft_match_statistics?mid=',''))\n",
    "            )\n",
    "    except urllib.error.URLError:\n",
    "        print('No internet connection')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./afl_DF.pkl'):\n",
    "    afl_DF = pd.read_pickle('afl_DF.pkl')\n",
    "\n",
    "if 'afl_DF' in locals():\n",
    "    scraped_ids = list(afl_DF.loc[0:]['fw_game_id'].astype('int'))\n",
    "    game_ids = [x for x in game_ids if x not in scraped_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n",
      "2019 2\n"
     ]
    }
   ],
   "source": [
    "for game_id in game_ids:\n",
    "    #scrape the data from the game page on footywire.com\n",
    "    game_id =  str(game_id)\n",
    "    afl_url = 'https://www.footywire.com/afl/footy/ft_match_statistics?mid=' + game_id\n",
    "    try:\n",
    "        soup = getSoup(afl_url)\n",
    "    except:\n",
    "        continue\n",
    "    new_game = scrapeGameData(soup) \n",
    "    if 'afl_update' not in locals():\n",
    "        afl_update = new_game\n",
    "    else:\n",
    "        afl_update  = afl_update.append(new_game, ignore_index=True)\n",
    "    sys.stdout.flush()\n",
    "    print(min(new_game.year),\n",
    "    min(new_game.round_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'afl_update' in locals():\n",
    "    if 'afl_DF' not in locals():\n",
    "        afl_DF = afl_update\n",
    "    else:\n",
    "        afl_DF = afl_DF.append(afl_update, ignore_index = True, sort = True)\n",
    "    afl_DF.to_pickle('afl_DF.pkl')    \n",
    "    del afl_update\n",
    "else:\n",
    "    print('afl_update does not exist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
